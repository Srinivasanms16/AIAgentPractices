{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49173bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Explain the ethical implications of using deepfake technology in political campaigns, providing a balanced view of potential benefits and harms, and suggest strategies for responsible use and regulation of this technology.\"\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\",api_key=os.getenv(\"OPENROUTER_API_KEY\"))\n",
    "questionchat = client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Give me one challenging, nuanced question through which i can evaluate the LLM model.Just the Question no more explanation\"}]\n",
    ")\n",
    "\n",
    "question = questionchat.choices[0].message.content \n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cd3d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Explain the ethical implications of using deepfake technology in political campaigns, providing a balanced view of potential benefits and harms, and suggest strategies for responsible use and regulation of this technology.\"\n",
      "Question: Let g(t) = 439 - 20*t. Let h be g(22). Let n = h - -440. Which is bigger: n or 5?\n",
      "Answer: n\n"
     ]
    }
   ],
   "source": [
    "#question = questionchat.choices[0].message.content \n",
    "print(question)\n",
    "answer1 = client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    messages=[{\"role\":\"user\",\"Content\":question}]\n",
    ")\n",
    "\n",
    "print(answer1.choices[0].message.content)\n",
    "\n",
    "model = []\n",
    "modelresponse = []\n",
    "model.append(\"mistralai/mistral-7b-instruct\")\n",
    "modelresponse.append(answer1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e80f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Ethical Implications of Deepfake Technology in Political Campaigns\n",
      "\n",
      "Deepfake technology—AI-generated synthetic media that manipulates audio, video, or images to depict false scenarios—poses profound ethical challenges in political campaigns. While it offers innovative opportunities, its misuse threatens democratic integrity. Below is a balanced analysis of its implications, followed by strategies for responsible use and regulation.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Potential Harms and Ethical Concerns**\n",
      "1. **Misinformation and Deception**:\n",
      "   - **Harm**: Deepfakes can fabricate speeches, actions, or scandals, misleading voters and distorting public debate. For example, a fake video of a candidate endorsing extremist views could sway opinions unfairly.\n",
      "   - **Ethical Issue**: Undermines informed consent and voter autonomy, as decisions are based on falsehoods.\n",
      "\n",
      "2. **Erosion of Trust**:\n",
      "   - **Harm**: Proliferation of deepfakes may lead to \"reality apathy,\" where voters distrust *all* media, including legitimate reporting (\"liar’s dividend\").\n",
      "   - **Ethical Issue**: Degrades democratic discourse and institutional credibility.\n",
      "\n",
      "3. **Targeted Manipulation**:\n",
      "   - **Harm**: Hyper-personalized deepfake messages could exploit voter biases (e.g., tailored ads showing a candidate attacking a specific community).\n",
      "   - **Ethical Issue**: Amplifies polarization and discrimination while circumventing accountability.\n",
      "\n",
      "4. **Consent and Privacy Violations**:\n",
      "   - **Harm**: Using a politician’s likeness without permission infringes on personal rights.\n",
      "   - **Ethical Issue**: Raises questions about ownership of one’s identity in the digital age.\n",
      "\n",
      "5. **Unequal Access**:\n",
      "   - **Harm**: Well-funded campaigns or malicious actors (e.g., foreign entities) could weaponize deepfakes, tilting the electoral playing field.\n",
      "   - **Ethical Issue**: Exacerbates power imbalances in democracies.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Potential Benefits**\n",
      "1. **Creative Advocacy**:\n",
      "   - **Benefit**: Deepfakes could resurrect historical figures (e.g., MLK Jr. advocating for voting rights) or simulate policy outcomes (e.g., climate change impacts) to inspire engagement.\n",
      "   - **Ethical Upside**: Enhances education and emotional resonance if transparently labeled.\n",
      "\n",
      "2. **Accessibility**:\n",
      "   - **Benefit**: Candidates could deliver multilingual or personalized messages to diverse constituencies without costly production.\n",
      "   - **Ethical Upside**: Fosters inclusivity and representation.\n",
      "\n",
      "3. **Satire and Commentary**:\n",
      "   - **Benefit**: Parody deepfakes (e.g., humorous critiques of hypocrisy) could enrich political discourse.\n",
      "   - **Ethical Upside**: Protected as free expression if clearly fictional and non-deceptive.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Strategies for Responsible Use and Regulation**\n",
      "To mitigate harms while preserving innovation, a multi-stakeholder approach is essential:\n",
      "\n",
      "1. **Legal and Regulatory Measures**:\n",
      "   - **Ban Malicious Use**: Laws criminalizing deepfakes intended to deceive voters (e.g., *Texas’s 2019 law* penalizing election-influencing deepfakes).\n",
      "   - **Mandatory Disclosure**: Require clear labels (e.g., \"AI-generated\") for synthetic media in political ads.\n",
      "   - **Platform Accountability**: Hold social media companies liable for rapid removal of deceptive deepfakes (similar to EU’s Digital Services Act).\n",
      "\n",
      "2. **Technological Safeguards**:\n",
      "   - **Detection Tools**: Fund AI-driven forensic tools (e.g., Adobe’s Content Authenticity Initiative) to identify deepfakes.\n",
      "   - **Watermarking**: Embed tamper-proof metadata in synthetic media, as proposed by the Coalition for Content Provenance and Authenticity (C2PA).\n",
      "\n",
      "3. **Media Literacy and Public Education**:\n",
      "   - **Critical Awareness**: Governments and NGOs should train voters to spot deepfakes (e.g., Indonesia’s pre-election literacy campaigns).\n",
      "   - **Fact-Checking Partnerships**: Expand platforms like AFP Fact Check to debunk political deepfakes in real time.\n",
      "\n",
      "4. **Ethical Guidelines for Campaigns**:\n",
      "   - **Voluntary Codes**: Political parties could adopt pledges to avoid deceptive AI (e.g., Aspen Institute’s Ethical Guidelines for AI in Elections).\n",
      "   - **Transparency**: Disclose AI use in campaign materials and limit micro-targeting to reduce manipulation risks.\n",
      "\n",
      "5. **Global Cooperation**:\n",
      "   - **Cross-Border Frameworks**: Address foreign interference via treaties or agreements (e.g., OECD’s AI Principles).\n",
      "   - **Independent Oversight**: Create regulatory bodies (e.g., a \"Digital Integrity Commission\") to audit political deepfakes.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Balancing Innovation and Protection**\n",
      "Deepfake technology in politics epitomizes the double-edged sword of AI: it can democratize engagement or destabilize democracies. Success hinges on **transparency**, **accountability**, and **collaboration** among lawmakers, tech innovators, civil society, and voters. By prioritizing ethical guardrails without stifling creativity, societies can harness AI’s potential while safeguarding electoral integrity.\n"
     ]
    }
   ],
   "source": [
    "answer2 = client.chat.completions.create(\n",
    "    model=\"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    messages=[{\"role\":\"user\",\"content\":question}]\n",
    ")\n",
    "\n",
    "print(answer2.choices[0].message.content)\n",
    "model.append(\"tngtech/deepseek-r1t2-chimera:free\")\n",
    "modelresponse.append(answer2.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bd4830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the explanation of the ethical implications of using deepfake technology in political campaigns:\n",
      "\n",
      "**Potential Benefits:**\n",
      "\n",
      "* **Increased reach:** Deepfakes can be used to reach a wider audience by creating realistic videos with influential figures endorsing specific candidates or ideologies.\n",
      "* **Enhanced credibility:** Deepfakes can be used to restore the credibility of a political candidate or party facing scandals or negative press.\n",
      "* **Targeted messaging:** Deepfakes can be tailored to specific audiences, allowing politicians to make personalized appeals.\n",
      "\n",
      "**Potential Harms:**\n",
      "\n",
      "* **Disinformation:** Deepfakes can spread false or misleading information, potentially influencing public opinion and elections.\n",
      "* **Manipulation:** Deepfakes can be used to create videos that exaggerate a candidate's support or target voters with negative messages.\n",
      "* **Bias:** Deepfakes can perpetuate biases and prejudices, leading to unfair or discriminatory outcomes.\n",
      "* **Moral concerns:** Deepfakes can be used to target vulnerable populations, such as women, minorities, or the elderly.\n",
      "\n",
      "**Strategies for Responsible Use and Regulation:**\n",
      "\n",
      "* **Transparency:** Clear and transparent labeling of deepfake videos is essential to distinguish them from authentic content.\n",
      "* **Accountability:** Developers and platforms should be held accountable for the use of deepfakes to ensure fair and ethical operation.\n",
      "* **Educational efforts:** Educational programs can help the public identify and evaluate deepfakes to promote critical thinking.\n",
      "* **Regulation:** Governments can consider regulations, such as stricter rules regarding transparency and accountability of deepfake producers and platforms.\n",
      "* **International cooperation:** Global efforts are needed to develop standardized policies and promote responsible use of deepfake technology in political campaigns.\n",
      "\n",
      "By implementing these strategies, we can mitigate the ethical risks associated with deepfake technology in political campaigns and promote a more fair, inclusive, and transparent political process.\n",
      "\n",
      "**Additional Considerations:**\n",
      "\n",
      "* The impact of deepfakes on political discourse and the democratic process is complex and multifaceted.\n",
      "* Defining what constitutes acceptable and unacceptable use of deepfakes is challenging, as it depends on factors such as their intent, context, and the intended audience.\n",
      "* Balancing the freedom of expression with the need to protect users and prevent harm requires careful consideration.\n"
     ]
    }
   ],
   "source": [
    "ollamaLLM = OpenAI(base_url=\"http://localhost:11434/v1\",api_key=\"Ollama\")\n",
    "answer3 = ollamaLLM.chat.completions.create(model=\"gemma:2b\",\n",
    "messages=[{\"role\":\"user\",\"content\":question}])\n",
    "print(answer3.choices[0].message.content)\n",
    "model.append(\"gemma:2b\")\n",
    "modelresponse.append(answer3.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98caef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Best Model:** `tngtech/deepseek-r1t2-chimera:free`  \n",
      "\n",
      "**Reason:**  \n",
      "- Provides a **comprehensive, balanced analysis** of ethical implications, clearly outlining both harms (e.g., misinformation, erosion of trust) and benefits (e.g., creative advocacy, accessibility).  \n",
      "- **Specific examples** (e.g., fake endorsements, MLK Jr. resurrection) and **ethical frameworks** enhance clarity.  \n",
      "- **Actionable strategies** for regulation (e.g., mandatory disclosure, watermarking) and responsible use (e.g., media literacy campaigns, global cooperation) are detailed and practical.  \n",
      "- **Outperforms** the other models:  \n",
      "  - `mistralai/mistral-7b-instruct`: Irrelevant response (answered a math question).  \n",
      "  - `gemma:2b`: Offers valid points but lacks depth, structure, and concrete examples compared to `deepseek-r1t2-chimera`.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#tuple(model)\n",
    "#tuple(modelresponse)\n",
    "results = zip(model,modelresponse)\n",
    "finalresult = dict(tuple(results))\n",
    "import json\n",
    "Summary = json.dumps(finalresult,indent=2)\n",
    "\n",
    "feval = f\"\"\"\n",
    "Evaluate my models on the basis of {question}.\n",
    "Their name and respose are give in the JSON format {Summary}.\n",
    "just give me Model name that is best in answering the question.\n",
    "\"\"\"\n",
    "\n",
    "fevalresponse = client.chat.completions.create(\n",
    "    model=\"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    messages=[{\"role\":\"user\",\"content\":feval}]\n",
    ")\n",
    "\n",
    "print(fevalresponse.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
